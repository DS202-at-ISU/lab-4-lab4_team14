---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit the README.Rmd file -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(ggplot2)
```

# Lab report #4 - instructions

Follow the instructions posted at <https://ds202-at-isu.github.io/labs.html> for the lab assignment. The work is meant to be finished during the lab time, but you have time until Monday (after Thanksgiving) to polish things.

All submissions to the github repo will be automatically uploaded for grading once the due date is passed. Submit a link to your repository on Canvas (only one submission per team) to signal to the instructors that you are done with your submission.

# Lab 4: Scraping (into) the Hall of Fame


```{r echo=FALSE, message=FALSE, warning=FALSE}
hof <- Lahman::HallOfFame
hof %>% 
  ggplot(aes(x = yearID, y = votes/needed*100, group=playerID)) +
  geom_hline(yintercept = 100, colour="grey70") + 
  geom_line() +
  geom_point(aes(colour = "inducted"), 
    data = hof %>% filter(inducted=="Y")) +
  xlim(c(2000, 2022)) +
  ylab("Percent of votes")
```

```{r}
#view the rows of original table
head(hof, 3)

hof <- select(hof, playerID, votes, yearID)
head(hof, 3)
```


```{r}
library(rvest)
url <- "https://www.baseball-reference.com/awards/hof_2023.shtml"
html <- read_html(url)
tables <- html_table(html)
```

```{r}
#view the scraped table
write.csv(tables[[1]], "temp.csv", row.names=FALSE)
backin <- readr::read_csv("temp.csv", skip = 1, show_col_types =FALSE)
head(backin, 3)
```

```{r}
#clean scraped data
backin <- select(backin, Name, Votes)
backin$yearID <- 2023

#change names and order to match
backin <- backin %>%
  rename(playerID = Name, votes = Votes)

head(backin, 3)
```

```{r}
#combine using rbind
updated_hof <- rbind(hof, backin)

write.csv(updated_hof, file="hof2023", row.names = FALSE)
```

